Metadata-Version: 2.1
Name: livekit-plugins-openai
Version: 0.10.7
Summary: Agent Framework plugin for services from OpenAI
Home-page: https://github.com/livekit/agents
License: Apache-2.0
Project-URL: Documentation, https://docs.livekit.io
Project-URL: Website, https://livekit.io/
Project-URL: Source, https://github.com/livekit/agents
Keywords: webrtc,realtime,audio,video,livekit
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Topic :: Multimedia :: Sound/Audio
Classifier: Topic :: Multimedia :: Video
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3 :: Only
Requires-Python: >=3.9.0
Description-Content-Type: text/markdown
Requires-Dist: livekit-agents[codecs,images] >=0.11
Requires-Dist: openai >=1.50

# LiveKit Plugins OpenAI

Agent Framework plugin for services from OpenAI. Currently supports STT, TTS, and Dalle 3.

## Installation

```bash
pip install livekit-plugins-openai
```

## Pre-requisites

You'll need an API key from OpenAI. It can be set as an environment variable: `OPENAI_API_KEY`

## OpenAI Beta Features

### Assistants API

In addition to LLM, STT, and TTS, this package also supports using [OpenAI's Assistants API](https://platform.openai.com/docs/assistants/overview) as a LLM.

The Assistants API is a stateful API that holds the conversation state on the server-side.

The `AssistantLLM` class gives you a LLM-like interface to interact with the Assistant API.

For examples of using Assistants API with VoicePipelineAssistant, see the [openai assistants API example](https://github.com/livekit/agents/blob/main/examples/voice-pipeline-agent/openai_assistant.py)
